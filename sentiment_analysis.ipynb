{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m1YVRhnWNBhn"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### loading training and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QyM8xw5SNBhr"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(r'./Corona_NLP_train.csv',encoding='latin-1')\n",
        "test = pd.read_csv(r'./Corona_NLP_test.csv',encoding='latin-1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q5wudePNBhs",
        "outputId": "2994f547-9afa-4f1e-b8dd-7429302c3d54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset rows & col : (41157, 6)\n",
            "Test dataset rows & col     : (3798, 6)\n"
          ]
        }
      ],
      "source": [
        "print('Training dataset rows & col :',train.shape)  # checking shape of our data\n",
        "print('Test dataset rows & col     :',test.shape)  # checking shape of our data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "qKSty3BVNBhu",
        "outputId": "424a4317-59a9-4774-b3ce-a9c8720746de"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserName  ScreenName   Location     TweetAt  \\\n",
              "0      3799       48751     London  16-03-2020   \n",
              "1      3800       48752         UK  16-03-2020   \n",
              "2      3801       48753  Vagabonds  16-03-2020   \n",
              "3      3802       48754        NaN  16-03-2020   \n",
              "4      3803       48755        NaN  16-03-2020   \n",
              "\n",
              "                                       OriginalTweet           Sentiment  \n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
              "1  advice Talk to your neighbours family to excha...            Positive  \n",
              "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
              "3  My food stock is not the only one which is emp...            Positive  \n",
              "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "zIc8I8b1NBhv",
        "outputId": "00bb3cff-ad8c-4215-f6c4-e87fdeba492e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>44953</td>\n",
              "      <td>NYC</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>44954</td>\n",
              "      <td>Seattle, WA</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>44955</td>\n",
              "      <td>NaN</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>Find out how you can protect yourself and love...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>44956</td>\n",
              "      <td>Chicagoland</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>44957</td>\n",
              "      <td>Melbourne, Victoria</td>\n",
              "      <td>03-03-2020</td>\n",
              "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3793</th>\n",
              "      <td>3794</td>\n",
              "      <td>48746</td>\n",
              "      <td>Israel ??</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3794</th>\n",
              "      <td>3795</td>\n",
              "      <td>48747</td>\n",
              "      <td>Farmington, NM</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Did you panic buy a lot of non-perishable item...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3795</th>\n",
              "      <td>3796</td>\n",
              "      <td>48748</td>\n",
              "      <td>Haverford, PA</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Asst Prof of Economics @cconces was on @NBCPhi...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3796</th>\n",
              "      <td>3797</td>\n",
              "      <td>48749</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Gov need to do somethings instead of biar je r...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3797</th>\n",
              "      <td>3798</td>\n",
              "      <td>48750</td>\n",
              "      <td>Arlington, Virginia</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>I and @ForestandPaper members are committed to...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3798 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      UserName  ScreenName             Location     TweetAt  \\\n",
              "0            1       44953                  NYC  02-03-2020   \n",
              "1            2       44954          Seattle, WA  02-03-2020   \n",
              "2            3       44955                  NaN  02-03-2020   \n",
              "3            4       44956          Chicagoland  02-03-2020   \n",
              "4            5       44957  Melbourne, Victoria  03-03-2020   \n",
              "...        ...         ...                  ...         ...   \n",
              "3793      3794       48746            Israel ??  16-03-2020   \n",
              "3794      3795       48747       Farmington, NM  16-03-2020   \n",
              "3795      3796       48748        Haverford, PA  16-03-2020   \n",
              "3796      3797       48749                  NaN  16-03-2020   \n",
              "3797      3798       48750  Arlington, Virginia  16-03-2020   \n",
              "\n",
              "                                          OriginalTweet           Sentiment  \n",
              "0     TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n",
              "1     When I couldn't find hand sanitizer at Fred Me...            Positive  \n",
              "2     Find out how you can protect yourself and love...  Extremely Positive  \n",
              "3     #Panic buying hits #NewYork City as anxious sh...            Negative  \n",
              "4     #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  \n",
              "...                                                 ...                 ...  \n",
              "3793  Meanwhile In A Supermarket in Israel -- People...            Positive  \n",
              "3794  Did you panic buy a lot of non-perishable item...            Negative  \n",
              "3795  Asst Prof of Economics @cconces was on @NBCPhi...             Neutral  \n",
              "3796  Gov need to do somethings instead of biar je r...  Extremely Negative  \n",
              "3797  I and @ForestandPaper members are committed to...  Extremely Positive  \n",
              "\n",
              "[3798 rows x 6 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGJpvSuqNBhw",
        "outputId": "f9c96a6c-ab76-472d-c38e-7b3912543145"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "UserName            0\n",
              "ScreenName          0\n",
              "Location         8590\n",
              "TweetAt             0\n",
              "OriginalTweet       0\n",
              "Sentiment           0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.isna().sum() # checking for null values in training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaZR7vCNNBhx",
        "outputId": "b9ac231c-a9f8-4473-c45c-32db441c4423"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "UserName           0\n",
              "ScreenName         0\n",
              "Location         834\n",
              "TweetAt            0\n",
              "OriginalTweet      0\n",
              "Sentiment          0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.isna().sum() # checking for null values in test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFwxNWhONBhy"
      },
      "source": [
        "- for sentiment analysis we don't need columns like username, screename, location and tweet at\n",
        "- as username here is index only & screen name too is random increment of integers\n",
        "- also location having too many null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZwrtFprRNBh0"
      },
      "outputs": [],
      "source": [
        "train = train.drop(columns=['UserName', 'ScreenName', 'Location', 'TweetAt'])\n",
        "test = test.drop(columns=['UserName', 'ScreenName', 'Location', 'TweetAt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEd4QHraNBh2",
        "outputId": "796a1ce1-9e1f-4cbd-f322-e0b8aec010c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Neutral', 'Positive', 'Extremely Negative', 'Negative',\n",
              "       'Extremely Positive'], dtype=object)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train['Sentiment'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_5lqyutNBh3",
        "outputId": "706f8822-42a8-40fb-e18b-860ac8c42414"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sentiment\n",
              "Positive              11422\n",
              "Negative               9917\n",
              "Neutral                7713\n",
              "Extremely Positive     6624\n",
              "Extremely Negative     5481\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train['Sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJhP_H3UNBh4",
        "outputId": "6dd92ad4-f37f-4f3f-97fa-678b90e06906"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Extremely Negative', 'Positive', 'Extremely Positive', 'Negative',\n",
              "       'Neutral'], dtype=object)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test['Sentiment'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "155GklR-NBh4",
        "outputId": "fdac5e9e-c840-4e95-b83c-c1a91008077f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sentiment\n",
              "Negative              1041\n",
              "Positive               947\n",
              "Neutral                619\n",
              "Extremely Positive     599\n",
              "Extremely Negative     592\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test['Sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vVkVdio3ULTl"
      },
      "outputs": [],
      "source": [
        "# function for clearing the tweets phrases in tweet columns\n",
        "def cleaning(data):\n",
        "    df = data.copy()\n",
        "    df.columns = map(str.lower, df.columns)\n",
        "\n",
        "    def remove_web_urls(text): return re.sub(r'https?://\\S+', ' ', text)\n",
        "    df['originaltweet'] = df['originaltweet'].apply(remove_web_urls)\n",
        "\n",
        "    def remove_tags(text): return re.sub(r'@\\w*', ' ' , text)\n",
        "    df['originaltweet'] = df['originaltweet'].apply(remove_tags)\n",
        "\n",
        "    def remove_hashtags(text): return re.sub(r'#\\w*', ' ' , text)\n",
        "    df['originaltweet'] = df['originaltweet'].apply(remove_hashtags)\n",
        "\n",
        "    def remove_apostrophe(text): return re.sub(r\"'s\\b\", \"\", text)\n",
        "    df['originaltweet'] = df['originaltweet'].apply(remove_apostrophe)\n",
        "\n",
        "    def remove_special_chars(text): return re.sub(r\"[^a-zA-Z0-9\\s]\", ' ', text)\n",
        "    df['originaltweet'] = df['originaltweet'].apply(remove_special_chars)\n",
        "\n",
        "    def remove_number(text): return re.sub(r'[\\d]', ' ', text)\n",
        "    df['originaltweet'] = df['originaltweet'].apply(remove_number)\n",
        "\n",
        "    df['originaltweet'] = df['originaltweet'].str.lower()\n",
        "    return df\n",
        "\n",
        "cleaned_train = cleaning(train)\n",
        "cleaned_test = cleaning(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0e6jj5UVb-h",
        "outputId": "0aa2f15e-2be4-4c0b-96b6-4e7a8126bbad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(                                           originaltweet           sentiment\n",
              " 0                                            and   and               Neutral\n",
              " 1      advice talk to your neighbours family to excha...            Positive\n",
              " 2      coronavirus australia  woolworths to give elde...            Positive\n",
              " 3      my food stock is not the only one which is emp...            Positive\n",
              " 4      me  ready to go at supermarket during the   ou...  Extremely Negative\n",
              " ...                                                  ...                 ...\n",
              " 41152  airline pilots offering to stock supermarket s...             Neutral\n",
              " 41153  response to complaint not provided citing covi...  Extremely Negative\n",
              " 41154  you know it  s getting tough when    is ration...            Positive\n",
              " 41155  is it wrong that the smell of hand sanitizer i...             Neutral\n",
              " 41156    well new used rift s are going for         o...            Negative\n",
              " \n",
              " [41157 rows x 2 columns],\n",
              "                                           originaltweet           sentiment\n",
              " 0     trending  new yorkers encounter empty supermar...  Extremely Negative\n",
              " 1     when i couldn t find hand sanitizer at fred me...            Positive\n",
              " 2     find out how you can protect yourself and love...  Extremely Positive\n",
              " 3       buying hits   city as anxious shoppers stock...            Negative\n",
              " 4                               one week everyone bu...             Neutral\n",
              " ...                                                 ...                 ...\n",
              " 3793  meanwhile in a supermarket in israel    people...            Positive\n",
              " 3794  did you panic buy a lot of non perishable item...            Negative\n",
              " 3795  asst prof of economics   was on   talking abou...             Neutral\n",
              " 3796  gov need to do somethings instead of biar je r...  Extremely Negative\n",
              " 3797  i and   members are committed to the safety of...  Extremely Positive\n",
              " \n",
              " [3798 rows x 2 columns])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_train, cleaned_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dMFZJPVCWMq6"
      },
      "outputs": [],
      "source": [
        "cleaned_train['sentiment'] = cleaned_train['sentiment'].str.replace('Extremely Positive', 'Positive') # replacing all Extremely Positive to positive\n",
        "cleaned_train['sentiment'] = cleaned_train['sentiment'].str.replace('Extremely Negative', 'Negative') # replacing all Extremely Negative to negative\n",
        "\n",
        "cleaned_test['sentiment'] = cleaned_test['sentiment'].str.replace('Extremely Positive', 'Positive') # replacing all Extremely Positive to positive\n",
        "cleaned_test['sentiment'] = cleaned_test['sentiment'].str.replace('Extremely Negative', 'Negative') # replacing all Extremely Negative to negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Qe7O0UWnWtBm"
      },
      "outputs": [],
      "source": [
        "# importing sklearn required libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ojKBgiP_WMlj"
      },
      "outputs": [],
      "source": [
        "X = cleaned_train['originaltweet'] # learing variable\n",
        "y = cleaned_train['sentiment'] # outcome varibale\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42) # splitting and forming variables for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrmdFnEsWMf6",
        "outputId": "36733484-9f2e-4565-951d-994ab455db7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((32925,), (8232,), (32925,), (8232,))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape # shape of all varibales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "W_IrbshLWMeK"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer() # intializing function\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train) # fitting and transforming train dataset\n",
        "X_val_vectorized = vectorizer.transform(X_val)  # fitting and transforming test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1LA8IBxWMaC",
        "outputId": "a25fbe36-13fc-48b2-b3e6-c6708a64f11b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6922983479105929\n"
          ]
        }
      ],
      "source": [
        "model = MultinomialNB() # intializing naive bayes\n",
        "model.fit(X_train_vectorized, y_train) # fitting model with traing dataset\n",
        "y_pred = model.predict(X_val_vectorized) # predicting and assignig to a function\n",
        "\n",
        "accuracy = accuracy_score(y_val, y_pred) # checking accuracy of the function\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IN4KvctiW-Mh"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# importing required tensorflow libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embedding, LSTM, Dense\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "# importing required tensorflow libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UCWd_n0WMXs",
        "outputId": "7874866c-0311-4541-b8e3-487e8872a98d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1029/1029 [==============================] - 309s 297ms/step - loss: 0.7041 - accuracy: 0.6854 - val_loss: 0.4188 - val_accuracy: 0.8575\n",
            "Epoch 2/5\n",
            "1029/1029 [==============================] - 301s 293ms/step - loss: 0.2896 - accuracy: 0.9070 - val_loss: 0.3806 - val_accuracy: 0.8817\n",
            "Epoch 3/5\n",
            "1029/1029 [==============================] - 300s 291ms/step - loss: 0.1791 - accuracy: 0.9438 - val_loss: 0.3861 - val_accuracy: 0.8761\n",
            "Epoch 4/5\n",
            "1029/1029 [==============================] - 294s 286ms/step - loss: 0.1144 - accuracy: 0.9626 - val_loss: 0.4608 - val_accuracy: 0.8716\n",
            "Epoch 5/5\n",
            "1029/1029 [==============================] - 295s 287ms/step - loss: 0.0713 - accuracy: 0.9766 - val_loss: 0.4786 - val_accuracy: 0.8797\n",
            "258/258 [==============================] - 24s 91ms/step\n",
            "Accuracy: 0.8797376093294461\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer() # initializing tokenizer\n",
        "tokenizer.fit_on_texts(X_train)  # fitting model with traing dataset\n",
        "\n",
        "# creating variables for tokenizer methods\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_sequences = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "# setting parameters for model\n",
        "max_sequence_length = 100\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
        "X_val_padded = pad_sequences(X_val_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# initializing labelencoder for transforming classification categorical columns\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)\n",
        "\n",
        "# initializing Sequential model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# setting tensorflow strategy\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "    mirrored_model = model\n",
        "\n",
        "# training the modal\n",
        "mirrored_model.fit(X_train_padded, y_train_encoded, validation_data=(X_val_padded, y_val_encoded), epochs=5, batch_size=32)\n",
        "\n",
        "# predicting from trained modal\n",
        "y_pred_probs = mirrored_model.predict(X_val_padded)\n",
        "y_pred_encoded = tf.argmax(y_pred_probs, axis=1).numpy()\n",
        "\n",
        "# scaling back to original categorical inputs\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "# checking accuracy of the modal\n",
        "accuracy = accuracy_score(y_val, y_pred_labels)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
